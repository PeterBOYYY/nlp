{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we created TFrecords from the bible. In the notebook we'll take a look at them and then build a model that predicts the Book of the bible a verse came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from preppy import Preppy, RankPreppy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataset by reading the train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = tf.data.TFRecordDataset(['./train.tfrecord']).map(RankPreppy.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess =tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(next_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(x):\n",
    "    x['length_q'] = tf.expand_dims(tf.convert_to_tensor(x['length_q']),0)\n",
    "    x['length_a'] = tf.expand_dims(tf.convert_to_tensor(x['length_a']),0)\n",
    "    x['label'] = tf.expand_dims(tf.convert_to_tensor(x['label']),0)\n",
    "    x['user'] = tf.expand_dims(tf.convert_to_tensor(x['user']),0)\n",
    "    return x\n",
    "def deflate(x):\n",
    "    x['length_q'] = tf.squeeze(x['length_q'])\n",
    "    x['length_a'] = tf.squeeze(x['length_a'])\n",
    "    x['label'] = tf.squeeze(x['label'])\n",
    "    x['user'] = tf.squeeze(x['user'])\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iter = dataset.map(expand).padded_batch(32,padded_shapes={\n",
    "    \"label\":1,\n",
    "    \"length_q\":1,\n",
    "    \"length_a\":1,\n",
    "    \"user\":1,\n",
    "    \"query\":tf.TensorShape([None]),\n",
    "    \"response\":tf.TensorShape([None])\n",
    "}).map(deflate)\n",
    "next_item = batch_iter.repeat().make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(next_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,inputs):\n",
    "        query =  inputs['query']\n",
    "        response =  inputs['response']\n",
    "        length_q = inputs['length_q']\n",
    "        length_a = inputs['length_a']\n",
    "        label = inputs['label']\n",
    "        user = inputs['user']\n",
    "        \n",
    "        self.lr = tf.placeholder(shape=None,dtype=tf.float32)\n",
    "        \n",
    "        emb_vec_word = tf.get_variable(\"emb_word\",dtype=tf.float32,shape=[74,32])\n",
    "        emb_vec_user = tf.get_variable(\"emb_user\",dtype=tf.float32,shape=[101,50])\n",
    "        emb_query = tf.nn.embedding_lookup(emb_vec_word, query)\n",
    "        emb_response = tf.nn.embedding_lookup(emb_vec_word, response)\n",
    "        emb_user = tf.nn.embedding_lookup(emb_vec_user, user)\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.GRUCell(128)\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,emb_source,dtype=tf.float32,sequence_length=lengths)\n",
    "        \n",
    "        book_logits =  tf.contrib.layers.fully_connected(state,num_outputs=64,activation_fn=tf.tanh)\n",
    "        book_logits =  tf.contrib.layers.fully_connected(state,num_outputs=215,activation_fn=None)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(book_id,book_logits)\n",
    "        self.loss = tf.reduce_mean(loss)\n",
    "        opt = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train = opt.minimize(self.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model(next_item)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num =1\n",
    "import sys\n",
    "while True:\n",
    "    try:\n",
    "        _,loss = sess.run([M.train,M.loss],feed_dict={M.lr:0.0001})\n",
    "        num+=1\n",
    "        sys.stdout.write(\"\\r\" + str(loss))\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
